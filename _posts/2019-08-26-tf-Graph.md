---
title: "Tensorflow Graph1"
excerrpt: "머신러닝 공부[Tensorflow]"

categories:
  - 딥러닝
tags:
  - 딥러닝
  - 머신러닝
  - Tensorflow
last_modified_at: 2019-08-26T08:06:00-05:00
---
<br>

# Tensorflow Graph
- Model 구성
- Compile(activation, optimizer)
- Launch(run)
- Predict
<br>
<br>

## **Graph(Model)** <br>
#### keras에서 모델을 구성하는것처럼 Tensorflow에서 Graph(Model)을 구성
#### 계산을 어떻게 그래프화 할지
<br>

## __1. 1차원 입력모델__
<br>
### __[USAGE]__ <br>
```python
import tensorflow as tf

tf.set_random_seed(777)

# 데이터구성
x_train = [1,2,3]
y_train = [1,2,3]


# 모델구성
W = tf.Variable(tf.random_normal([1], name="weight"))
b = tf.Variable(tf.random_normal([1], name="bias"))

hypothesis = x_train * W + b
```
###### y = xw+b 식을 노드로 생성하여 Graph 구성
<br>

```python
# 모델 compile

## loss="mse"
cost = tf.reduce_mean(tf.square(hypothesis - y_train))
## optimizer="GradientDescent"
train = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)
```
<br>
```python
# Launch Graph
with tf.Session() as sess:
    ## 변수 초기화(필수)
    sess.run(tf.global_variables_initializer())

    ## fit
    for step in range(2001):    # epochs
        _, cost_val, W_val, b_val = sess.run([train, cost, W, b])# run=fit

        if step % 20 == 0:
            print(step, cost_val, W_val, b_val)
```
###### compile, fit, evaluate, predict 모두 Session 내에서 실행
###### 실행결과
![img1](/assets/images/tf_model1.png)
<br>
<br>

# __2. 다차원 입력 모델__ <br>
<br>
### __[USAGE]__ <br>
```python
import tensorflow as tf
tf.set_random_seed(777)

# 데이터구성
x_train = [[73,80,75],[96,88,93],[89,91,90],[96,98,100],[73,66,70]]
y_train = [[152],[185],[180],[196],[142]]


# 모델구성
X = tf.placeholder(tf.float32, shape=[None, 3])
Y = tf.placeholder(tf.float32, shape=[None, 1])

W = tf.Variable(tf.random_normal([1], name="weight"))
b = tf.Variable(tf.random_normal([1], name="bias"))

hypothesis = tf.matmul(X,W) + b

```
###### tf.matmul함수를 이용해서 다차원 입력. <br>
###### input, output 차원확인 필요
<br>

```python
# 모델 compile
cost = tf.reduce_mean(tf.square(hypothesis - y_train))
train = tf.train.GradientDescentOptimizer(learning_rate=1e-5).minimize(cost)    
```
<br>

```python
# model launch
with tf.Session() as sess:
    ## 변수 초기화
    sess.run(tf.global_variables_initializer())

    for step in range(2001):
        cost_val, hy_val, _ = sess.run([cost, hypothesis, train],
feed_dict={x:x_train, y:y_train)

    	if step % 10 == 0:
print(step, "Cost: ", cost_val, "\nPrediction: ",hy_val)
```
###### 실행결과
![img2](/assets/images/tf_model2.png)
<br>
<br>

## __3. 분류모델__ <br>
#### Sigmoid를 사용하여 분류모델 구성
<br>
### __[USAGE]__ <br>
```python
import tensorflow as tf
tf.set_random_seed(777)

# 데이터 구성
x_train = [[1,2],[2,3],[3,1],[4,3],[5,3],[6,2]]
y_train = [[0],[0],[0],[1],[1],[1]]


# 모델구성
X = tf.placeholder(tf.float32, shape=[None,2])
Y = tf.placeholder(tf.float32, shape=[None,1])

W = tf.Variable(tf.random_normal([2,1], name="weight"))
b = tf.Variable(tf.random_normal([1], name="bias"))

hypothesis = tf.sigmoid(matmul(X,W) + b)
```
###### y값을 one-hot encoding하여 분류모델에 사용
<br>

```python
# 모델 compile
cost = -tf.reduce_mean(Y*tf.log(hypothesis) + (1-Y) * tf.log(1-hypothesis))
train = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)

## 0.5보다 크면 1, 작으면 0
predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)
accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))
```
###### sigmoid에서 사용하는 binary_crossentropy 적용
###### tf.reduce_mean(tf.compat.v1.nn.sigmoid_cross_entropy_with_logits(logits=hypothesis, labels=Y)) >> 변경가능
###### predict, accuracy 적용
<br>

```python
# model Launch
with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())

    for step in range(10001):
        cost_val, _ = sess.run([cost, train], feed_dict={x:x_train, y:y_train)

    	if step % 10 == 0:
print(step, "Cost: ", cost_val)

    # accuracy
    h, c, a = sess.run([hypothesis, predicted, accuracy], fedd_dict={X:x_data, Y:y_data})
    print("Hypothesis :", h, "\nCorrect (Y) :", c, "\nAccuracy: ", a)
```
###### 실행결과
![img3](/assets/images/tf_sigmoid_model1.png)
<br>
<br>

## __4. 분류모델2__ <br>
#### softmax를 사용해서 분류모델 구성
<br>

### __[USAGE]__ <br>
```python
import tensorflow as tf
tf.set_random_seed(777)

# 데이터 구성
x_train = [1,2,1,1], [2,1,3,2], [3,1,3,4], [4,1,5,5], [1,7,5,5], [1,6,6,6], [1,7,7,7]]
y_train = [[0,0,1],[0,0,1],[0,0,1],[0,1,0],[0,1,0],[1,0,0],[1,0,0]]


# 모델 구성
X = tf.placeholder(tf.float32, shape=[None,4])
Y = tf.placeholder(tf.float32, shape=[None,3])

W = tf.Variable(tf.random_normal([4,3], name="weight"))
b = tf.Variable(tf.random_normal([3], name="bias"))

hypothesis = tf.nn.softmax(matmul(X,W) + b)
```
###### y값을 one-hot encoding하여 분류모델에 사용
<br>

```python
# 모델 compile
cost = tf.reduce_mean(-tf.reduce_sum(Y*tf.log(hypothesis), axis=1))
train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)    
```
###### softmax에서 사용하는 categorical_crossentropy 적용
###### cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=hypothesis, labels=Y) >> 변경가능
<br>

```python
# Launch graph
with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())

    for step in range(10001):
        cost_val, _ = sess.run([cost, train], feed_dict={x:x_train, y:y_train})

    	if step % 10 == 0:
print(step, cost_val)

    # one-hot encoding
    a = sess.run(hypothesis, feed_dict={X:[[1,11,7,9]]})
    print(a, sess.run(tf.argmax(a,1)))

    b = sess.run(hypothesis, feed_dict={X:[[1,3,4,3]]})
    print(b, sess.run(tf.argmax(b,1)))

c = sess.run(hypothesis, feed_dict={X:[[1,1,0,1]]})
    print(c, sess.run(tf.argmax(c,1)))

    all = sess.run(hypothesis, feed_dict={X:[[1,11,7,9],[1,3,4,5],[1,1,0,1]})
    print(all, sess.run(tf.argmax(all,1)))
```
###### 실행결과
![img4](/assets/images/tf_softmax_model1.png)
<br>
<br>
